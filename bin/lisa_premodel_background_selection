#!/usr/bin/env python
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import make_scorer, average_precision_score, roc_auc_score
from scipy.stats import uniform
import h5py
import fire
import os
import numpy as np
import fire
from lisa.data import EpigenomeData
from lisa.utils import binarize_gene_set
from lisa.model import Logit
from pkg_resources import resource_filename
from collections import Counter, defaultdict
from lisa import Config
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import random
import sys
np.random.seed(999)
random.seed(999)


def generate_dedup_refseq(s, e, g):
    epigenome = EpigenomeData(s, e)
    feature = epigenome.get_cluster_median
    refseq = feature.index.map(lambda x: x.split(':')[-2].upper())
    symbol = feature.index.map(lambda x: x.split(':')[-1].upper())
    gene_vec = binarize_gene_set(g, refseq, symbol)
    feature.loc[:, 'Y'] = gene_vec
    feature.loc[:, 'symbols'] = symbol
    feature_symbols = feature.drop_duplicates(subset='symbols', keep='first', inplace=False)
    feature_symbols = feature_symbols.drop('symbols', axis=1, inplace=False)
    return feature_symbols


def sampling_by_tad(prefix, species, epigenomes, df, excl_genes, incl_genes, num=3000):
    # 'chrY:57214703:57214704:NR_110561:DDX11L16'
    if len(excl_genes) > 0:
        background = df.loc[~df.geneName.map(lambda x:x.upper()).isin(excl_genes), :]
    else:
        background = df
    if len(incl_genes) > 0:
        background = background.loc[background.geneName.map(lambda x:x.upper()).isin(incl_genes), :]
    else:
        background = df

    background.drop_duplicates('geneName', inplace=True)
    tad_promoter_chr = background.loc[:, ['k4me3_order_cluster', 'tad_order_cluster']]
    prop_dict = Counter()
    prop_dict_genes = defaultdict(list)
    for i in range(tad_promoter_chr.shape[0]):
        prop_dict[tuple(tad_promoter_chr.iloc[i, :])] += 1
        prop_dict_genes[tuple(tad_promoter_chr.iloc[i, :])].append(background.iloc[i, :].geneName.upper())
    n = 0
    genes = []
    z = 0
    for i in prop_dict:
        # NOTE: class ratio < 1 will be ignored, add back below
        gene_num = int(prop_dict[i] / background.shape[0] * num * 1.1) # sampling a bit more genes
        #print(prop_dict[i] / background.shape[0])
        z += prop_dict[i] / background.shape[0]
        if gene_num == 0: ## in case TAD+promoter activity class ratio < 1, add one back
            gene_num += 1
        n += gene_num
        print(len(np.array(prop_dict_genes[i])), gene_num, 'check')
        if len(np.array(prop_dict_genes[i])) < gene_num:
            genes += list(np.random.choice(np.array(prop_dict_genes[i]), len(np.array(prop_dict_genes[i]))-1, replace=False)) # replace=False
        else:
            genes += list(np.random.choice(np.array(prop_dict_genes[i]), gene_num, replace=False)) # replace=False
    return list(set(genes))


def get_background(species, epigenomes, gene_set, prefix, random, background, stat_step_background_number):
    """ 
    background: background genes from user specified text file, one gene a row

    different background strategy:
    1. epigenetic background:  get background information by using regression of all input data of epigenome types
                               cluster center to get the predicted RP and get the 1000 nearest neighbors

    2. random background 
    3. TAD+promoter background: only available for human now
    """
    assert stat_step_background_number >= 20, 'background gene number for statistics should be larger than 20'

    if gene_set != None:
        feature_symbols = generate_dedup_refseq(species, epigenomes[0], gene_set)
        #feature_symbols.index = feature_symbols.index.map(lambda x:x.upper())

    if background != None:
        if background == 'dynamic_auto_tad':
            conf = Config(resource_filename("lisa", "lisa.ini"), species)
            df = pd.read_table(conf.get_tad)
            if gene_set != None:
                all_rp_genes = feature_symbols.index.map(lambda x:x.split(':')[-1].upper())
                df = df.loc[df.geneName.map(lambda x:x.upper()).isin(all_rp_genes), :] ## overlap TAD annotation with our RP genes
                foreground = feature_symbols.index[feature_symbols.Y==1].map(lambda x:x.split(':')[-1].upper())
            else:
                foreground = []
            background = sampling_by_tad(prefix, species, epigenomes, df, foreground, [])
            ## 3000 background genes in symbols
            np.savetxt('%s.background_gene.1' % prefix,
                       background, fmt="%s")
            get_background(species, epigenomes, gene_set, prefix, random, '%s.background_gene.1' % prefix, stat_step_background_number)
            return True
        elif os.path.exists(background):
            if gene_set != None:
                foreground = feature_symbols.index[feature_symbols.Y==1].values
                np.savetxt('%s.foreground_gene' % prefix,
                           foreground, fmt="%s")
                foreground = np.array(list(map(lambda x:x.split(':')[-1].upper(), foreground)))
            else:
                foreground = []
            background  = generate_dedup_refseq(species, epigenomes[0], background) ## only use Y here

            if (background.Y == 1).sum() >= 3000*1.05:
                if gene_set != None:
                    overlapped = ((background.Y == 1) & (feature_symbols.Y==1)).sum()
                    sampled_num = 3000 - overlapped # exclude 0.06% to 3% of background genes overlapped with input genes
                    background_genes = np.unique(np.random.choice(background.index[(background.Y == 1) & (feature_symbols.Y==0)].values, size=sampled_num, replace=False))
                else:
                    background_genes = np.unique(np.random.choice(background.index[(background.Y == 1)].values, size=3000, replace=False))

                conf = Config(resource_filename("lisa", "lisa.ini"), species)
                df = pd.read_table(conf.get_tad)
                sub_background_genes = sampling_by_tad(prefix, species, epigenomes, df, foreground, 
                                                       np.array(list(map(lambda x:x.split(':')[-1].upper(), background_genes))), stat_step_background_number)
                ## keep exactly stat_step_background_number number of background genes
                sub_background_genes = background_genes[np.in1d(np.array(list(map(lambda x:x.split(':')[-1].upper(), background_genes))), 
                                                                sub_background_genes)]
                print(len(sub_background_genes), 'total')
                if len(sub_background_genes) < stat_step_background_number: ## avoid sampling error caused by >=3000 stat_step_background_number
                    sub_background_genes = np.unique(np.random.choice(sub_background_genes, size=len(sub_background_genes)-1, replace=False))
                else:
                    sub_background_genes = np.unique(np.random.choice(sub_background_genes, size=stat_step_background_number, replace=False))
                np.savetxt('%s.background_gene.3000' % prefix,
                           background_genes, fmt="%s")
                np.savetxt('%s.background_gene.1000' % prefix,
                           sub_background_genes, fmt="%s")
            else:  # user customized gene set too few genes
                if gene_set != None:
                    assert ((background.Y == 1) & (feature_symbols.Y==0)).sum() >= 30, 'too few background genes, or background overlapped too much with target genes!'
                    background_genes = np.unique(background.index[(background.Y == 1) & (feature_symbols.Y==0)].values)
                else:
                    background_genes = np.unique(background.index[(background.Y == 1)])

                np.savetxt('%s.background_gene.3000' % prefix,
                           background_genes, fmt="%s")
                np.savetxt('%s.background_gene.1000' % prefix,
                           background_genes, fmt="%s")
        return True

    if gene_set == None:
        raise Exception('gene set must be specified with random and epigenetic background') 

    if not random:
        ## select background genes by using epigenome information of x marks
        rank_dict = {}
        for e in epigenomes:
            feature_symbols = generate_dedup_refseq(species, e, gene_set)
            ## feature_symbols.index = feature_symbols.index.map(lambda x:x.upper())
            feature_symbols_x = feature_symbols.iloc[:, :(feature_symbols.shape[1]-1)]
            feature_symbols_y = feature_symbols.Y
            scale = StandardScaler(with_std=False)
            feature_symbols_x = pd.DataFrame(scale.fit_transform(feature_symbols_x),
                                             columns=feature_symbols_x.columns,
                                             index=feature_symbols_x.index)
            fold = KFold(n_splits=3, shuffle=True, random_state=777)
            rng = np.random.RandomState(999)
            parameters = {'clf__C': rng.uniform(1e3, 1e8, 5)}
            logit = LogisticRegression(penalty='l1', tol=0.01, dual=False, random_state=999)
            lisa_expression_gs = GridSearchCV(Pipeline([('clf', logit)]),
                                              parameters, cv=fold, n_jobs=1,
                                              scoring=make_scorer(roc_auc_score))
            lisa_expression_gs.fit(feature_symbols_x, feature_symbols_y)
            prediction = lisa_expression_gs.predict_log_proba(feature_symbols_x)[:, 1]
            prauc = average_precision_score(feature_symbols_y, prediction)
            auc = roc_auc_score(feature_symbols_y, prediction)
            coefs = lisa_expression_gs.best_estimator_.named_steps['clf'].coef_[0]
            best_params = lisa_expression_gs.best_params_.get('clf__C', None)
            with open('%s.premodel_records.txt' % prefix, 'w') as cluster_regf:
                cluster_regf.write("%s\t%s\t%s\n" % (prauc, auc, best_params))
                cluster_regf.write('\t'.join(list(map(str, coefs))))
            rank_dict[e] = prediction

        np.savetxt('%s.foreground_gene' % prefix,
                   feature_symbols.index[feature_symbols.Y==1].values, fmt="%s")
        rank_df = pd.DataFrame(rank_dict, index=feature_symbols_x.index)
        rank_df = rank_df.rank(axis=0, ascending=False)
        prediction_control = rank_df.ix[feature_symbols_y==0, :]
        prediction_diff = rank_df.ix[feature_symbols_y==1, :]
        # control gene number matching one differential gene
        diff_gene = feature_symbols.index[feature_symbols.Y == 1]

        if len(diff_gene) <= 3000:
            control_gene_per_diff = 3000 // prediction_diff.shape[0]
        else:
            raise Exception('more genes than 3000...')

        background_genes = set()
        for fore_gene in diff_gene:
            # |rank_j K4me3 - rank_i K4me3| + | rank_j K27ac - rank_i K27ac | +  | rank_j GC - rank_i GC |
            dist = prediction_control.sub(prediction_diff.loc[fore_gene], axis=1) \
                                     .abs() \
                                     .sum(axis=1)
            dist.sort_values(axis=0, ascending=True, inplace=True)
            background_genes = background_genes.union(dist.index[:control_gene_per_diff])
    else:
        feature_symbols = generate_dedup_refseq(species, epigenomes[0], gene_set)
        ## feature_symbols.index = feature_symbols.index.map(lambda x:x.upper())
        np.savetxt('%s.foreground_gene' % prefix,
                   feature_symbols.index[feature_symbols.Y==1].values, fmt="%s")
        background_genes = np.random.choice(feature_symbols.index[feature_symbols.Y == 0], size=3000, replace=False)

    background_genes = np.array(list(background_genes))
    np.savetxt('%s.background_gene.3000' % prefix,
               background_genes, fmt="%s")
    np.savetxt('%s.background_gene.1000' % prefix,
               np.random.choice(background_genes, size=stat_step_background_number, replace=False), fmt="%s")
    return True

if __name__ == '__main__':
    fire.Fire(get_background)
